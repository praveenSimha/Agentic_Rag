
# ğŸ“„ Agentic RAG Chatbot

A Retrieval-Augmented Generation (RAG) chatbot with an **agentic architecture** and **Model Context Protocol (MCP)**. This system allows users to upload multi-format documents (PDF, DOCX, TXT, etc.) and ask natural language questions. The chatbot uses LLMs to answer based on the retrieved document chunks.

---

## ğŸ§  Features

- âœ… Agent-based modular design
- âœ… Handles PDFs, DOCX, TXT, CSV, PPTX, Markdown
- âœ… Ingestion, retrieval, and LLM-response agents
- âœ… DistilBERT from HuggingFace for QA
- âœ… Retrieval with semantic similarity (FAISS ready)
- âœ… Streamlit UI for interaction
- âœ… Context flow with Model Context Protocol (MCP)

---

## ğŸ—‚ï¸ Project Structure

```bash
Agentic_RAG/
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ ingestion_agent.py
â”‚   â”œâ”€â”€ retrieval_agent.py
â”‚   â””â”€â”€ llm_response_agent.py
â”œâ”€â”€ mcp/
â”‚   â””â”€â”€ protocol.py
â”œâ”€â”€ ui/
â”‚   â””â”€â”€ app.py
â”œâ”€â”€ main.py
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
````

---

## âš™ï¸ Installation

1. **Clone the repository:**

```bash
git clone https://github.com/praveenSimha/Agentic_Rag.git
cd agentic-rag-chatbot
```

2. **Create and activate a virtual environment (optional but recommended):**

```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. **Install dependencies:**

```bash
pip install -r requirements.txt
```

---

## ğŸš€ Run the Application

```bash
streamlit run ui/app.py
```

> You'll get a web-based interface where you can upload documents and ask questions.

---

## ğŸ§© Core Components

### `mcp/protocol.py`

Defines the `MCPMessage` structure and `create_mcp_message()` function.

### `agents/ingestion_agent.py`

Ingests the documents and chunks their content into manageable pieces.

### `agents/retrieval_agent.py`

Performs basic semantic similarity checks and selects top relevant chunks. Uses `ingest_documents_to_store()` internally.

### `agents/llm_response_agent.py`

Uses Hugging Faceâ€™s DistilBERT for question answering over the retrieved context.

### `main.py`

Coordinates all agents and implements the `run_query_pipeline()`.

### `ui/app.py`

Streamlit UI to upload files and input user queries.

---

## ğŸ§ª Supported File Formats

* `.pdf`
* `.docx`
* `.txt`
* `.csv`
* `.md`
* `.pptx`

---

## ğŸ§  Technologies Used

* Python
* Streamlit
* HuggingFace Transformers (`distilbert-base-uncased-distilled-squad`)
* FastAPI-style modular agents
* FAISS-ready architecture
* WebSockets & async-ready design (backend friendly)
* Model Context Protocol (custom coordination)

---

## ğŸ“Œ TODO / Improvements

* [ ] Integrate OpenAI / LLaMA-2 for better LLM responses
* [ ] Enable multi-agent coordination using LangChain
* [ ] Add logging and tracing via `trace_id`
* [ ] Add authentication for deployment

---

## ğŸ§‘â€ğŸ’» Author

**Praveen Gubbala**


ğŸ“« Connect: [LinkedIn](https://www.linkedin.com/in/gpln)

---

## ğŸ“„ License

This project is licensed under the MIT License.
Feel free to use and modify for educational or personal use.


